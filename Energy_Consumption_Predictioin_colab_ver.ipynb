{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c10b727",
      "metadata": {
        "id": "1c10b727"
      },
      "source": [
        "# Energy Consumption Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd0aebc",
      "metadata": {
        "id": "dbd0aebc"
      },
      "source": [
        "In this project, a deep learning model will be developed to predict the amount of energy consumed by a building with solar panel. The deep learning model will use tensorflow/keras framework. A baseline model (*Sequential Model*) and a proposed model (*Functional Model*) would be developed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dc64ea5",
      "metadata": {
        "id": "6dc64ea5"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<th>Column Name</th>\n",
        "<th>Description</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Month</td>\n",
        "<td>The month of the year when the data was recorded.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Hour</td>\n",
        "<td>The hour of the day when the data was recorded.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>DayOfWeek</td>\n",
        "<td>The day of the week when the data was recorded.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Holiday</td>\n",
        "<td>Indicates whether the day was a holiday (Yes/No).</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Temperature</td>\n",
        "<td>The average daily temperature in Celsius.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Humidity</td>\n",
        "<td>The average daily humidity level (%).</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>SquareFootage</td>\n",
        "<td>The area of the building being monitored in m<sup>2</sup>.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Occupancy</td>\n",
        "<td>The total number of people occupying the building.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>HVACUsage</td>\n",
        "<td>Indicates whether the HVAC system was in use (On/Off).</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>LightingUsage</td>\n",
        "<td>Indicates whether the lighting system was in use (On/Off).</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>RenewableEnergy</td>\n",
        "<td>The amount of renewable energy generated at the time of data collection. (Kwh)</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>EnergyConsumption (the goal)</td>\n",
        "<td>The amount of energy consumed at the time of data collection. (Kwh)</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12ff704",
      "metadata": {
        "id": "c12ff704"
      },
      "source": [
        "## Importing the Needed Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Needed Libraries"
      ],
      "metadata": {
        "id": "TSCWn9wE-tUV"
      },
      "id": "TSCWn9wE-tUV"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install pyarrow\n",
        "!pip install pynvml\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "1DaXstId-y7W"
      },
      "id": "1DaXstId-y7W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5382a738",
      "metadata": {
        "id": "5382a738"
      },
      "outputs": [],
      "source": [
        "# Basic python Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Data prepreocessing Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "# Tensorflow Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Embedding, Flatten, Input, Concatenate\n",
        "\n",
        "# Model Evaluation Libraries\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Hyperparameter tuning Libraries\n",
        "import optuna\n",
        "\n",
        "# Library for gpu utilization\n",
        "import pynvml\n",
        "\n",
        "# Library for cleaner notebook\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Check"
      ],
      "metadata": {
        "id": "BJhkhwgH_POc"
      },
      "id": "BJhkhwgH_POc"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "gtD8xyqeAMW1"
      },
      "id": "gtD8xyqeAMW1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Check if TensorFlow is using the GPU\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"TensorFlow is using the GPU\")\n",
        "\n",
        "    # Initialize the pynvml library\n",
        "    pynvml.nvmlInit()\n",
        "\n",
        "    # Get the number of GPU devices\n",
        "    num_gpus = pynvml.nvmlDeviceGetCount()\n",
        "\n",
        "    # Iterate over GPU devices\n",
        "    for i in range(num_gpus):\n",
        "        # Get the device identifier\n",
        "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
        "        # Get the full GPU name\n",
        "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
        "        print(\"GPU Name:\", gpu_name)\n",
        "\n",
        "    # Shutdown the pynvml library\n",
        "    pynvml.nvmlShutdown()\n",
        "else:\n",
        "    print(\"TensorFlow is not using the GPU\")"
      ],
      "metadata": {
        "id": "pcZ9ir4L_gJK"
      },
      "id": "pcZ9ir4L_gJK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "87348ad0",
      "metadata": {
        "id": "87348ad0"
      },
      "source": [
        "## Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cM6ayuPuAPKn"
      },
      "id": "cM6ayuPuAPKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c17d108",
      "metadata": {
        "id": "7c17d108"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"/content/drive/MyDrive/Energy_consumption_project/Dataset_01/dataset_1A.parquet\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a4730f",
      "metadata": {
        "id": "e6a4730f"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb19b807",
      "metadata": {
        "id": "fb19b807"
      },
      "source": [
        "### Check the Missing Values and Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4fc347c",
      "metadata": {
        "id": "b4fc347c"
      },
      "source": [
        "#### The Number of Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7739f8",
      "metadata": {
        "id": "cf7739f8"
      },
      "outputs": [],
      "source": [
        "missing_data_count = pd.DataFrame(data.isna().sum())\n",
        "missing_data_count.columns = [\"Number_Of_Data_Missing\"]\n",
        "missing_data_count[\"Percentage\"] = round(missing_data_count[\"Number_Of_Data_Missing\"]/len(data) * 100, 2)\n",
        "missing_data_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b6cec94",
      "metadata": {
        "id": "3b6cec94"
      },
      "source": [
        "#### Check for Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2b1a80",
      "metadata": {
        "id": "7b2b1a80"
      },
      "outputs": [],
      "source": [
        "print(data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e8f484",
      "metadata": {
        "id": "c8e8f484"
      },
      "source": [
        "### Check the Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2606ec83",
      "metadata": {
        "id": "2606ec83"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97b063a0",
      "metadata": {
        "id": "97b063a0"
      },
      "source": [
        "The data is roughly clean so far with some correct data types and no missing values. However the \"EnergyConsumption\" column has a wrong data type where it should be float64. Therefore, we will change that data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2d7210",
      "metadata": {
        "id": "1c2d7210"
      },
      "outputs": [],
      "source": [
        "# Changing the data type of \"EnergyConsumption\"\n",
        "data[\"EnergyConsumption\"] = data[\"EnergyConsumption\"].astype(\"float64\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc8905e",
      "metadata": {
        "id": "ecc8905e"
      },
      "outputs": [],
      "source": [
        "# Recheck the data types\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d62ee845",
      "metadata": {
        "id": "d62ee845"
      },
      "source": [
        "### Check if there are more missing data after conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea682ab7",
      "metadata": {
        "id": "ea682ab7"
      },
      "outputs": [],
      "source": [
        "missing_data_count = pd.DataFrame(data.isna().sum())\n",
        "missing_data_count.columns = [\"Number_Of_Data_Missing\"]\n",
        "missing_data_count[\"Percentage\"] = round(missing_data_count[\"Number_Of_Data_Missing\"]/len(data) * 100, 2)\n",
        "missing_data_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d455ffdc",
      "metadata": {
        "id": "d455ffdc"
      },
      "outputs": [],
      "source": [
        "# Since there are some missing values in the dataset, we need to handle them.\n",
        "data = data.dropna(axis=0)\n",
        "\n",
        "# Recheck the data\n",
        "missing_data_count = pd.DataFrame(data.isna().sum())\n",
        "missing_data_count.columns = [\"Number_Of_Data_Missing\"]\n",
        "missing_data_count[\"Percentage\"] = round(missing_data_count[\"Number_Of_Data_Missing\"]/len(data) * 100, 2)\n",
        "missing_data_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70112b7d",
      "metadata": {
        "id": "70112b7d"
      },
      "source": [
        "### Check the Range of the \"Hours\" Column\n",
        "\n",
        "Let's check the \"Hours\" to get the range of the time is it a 12 hour format or a 24 hour format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b706e508",
      "metadata": {
        "id": "b706e508"
      },
      "outputs": [],
      "source": [
        "min(data[\"Hour\"]), max(data[\"Hour\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd061783",
      "metadata": {
        "id": "cd061783"
      },
      "source": [
        "Looks like the data is in a 24 hour format so lets change it to a time format of HH:MM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc6e164",
      "metadata": {
        "id": "9bc6e164"
      },
      "source": [
        "### Plotting Data Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55f9c670",
      "metadata": {
        "id": "55f9c670"
      },
      "source": [
        "#### Functions for plotting the distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110e1d4a",
      "metadata": {
        "id": "110e1d4a"
      },
      "outputs": [],
      "source": [
        "#setting the colors generator\n",
        "def fill_color_generator():\n",
        "    \"\"\"This generates a color\n",
        "\n",
        "    Returns:\n",
        "        color: An R,G,B value with a range of 0 to 1\n",
        "    \"\"\"\n",
        "    r = random.randint(0, 255)\n",
        "    g = random.randint(0, 255)\n",
        "    b = random.randint(0, 255)\n",
        "    return (r/255, g/255, b/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c837e1",
      "metadata": {
        "id": "f1c837e1"
      },
      "outputs": [],
      "source": [
        "#function for plotting numerical data distribution\n",
        "def numeric_dist_plot(data: pd.DataFrame):\n",
        "    \"\"\"This function creates a plot of the distribution of the numerical data.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Numeric pandas dataframe\n",
        "\n",
        "    Raises:\n",
        "        TypeError: The following columns are not numeric: {non_numeric_cols}\n",
        "        This is due to some of the columns are not numeric.\n",
        "\n",
        "    Returns:\n",
        "        Displays a plot of\n",
        "    \"\"\"\n",
        "    # Checks\n",
        "    ## Check if all columns are numeric\n",
        "    non_numeric_cols = [col for col in data.columns if not pd.api.types.is_numeric_dtype(data[col])]\n",
        "    if non_numeric_cols:\n",
        "        raise TypeError(f\"The following columns are not numeric: {non_numeric_cols}\")\n",
        "\n",
        "    # Plotting the numerical data\n",
        "    #titles for plots/figures\n",
        "    fig_titles = []\n",
        "\n",
        "    for colName in data.columns:\n",
        "        fig_titles.append(f\"Boxplot Of {colName}\")\n",
        "        fig_titles.append(f\"Histogram Of {colName}\")\n",
        "\n",
        "    fill_color_dict = {}\n",
        "    for colName in data.columns:\n",
        "        fill_color_dict[colName] = fill_color_generator()\n",
        "\n",
        "    # make subplot for each column name\n",
        "    num_rows = len(data.columns)\n",
        "    fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, num_rows * 3))\n",
        "\n",
        "    # Flatten axes for easier indexing when there's more than 1 row\n",
        "    axes = axes if num_rows > 1 else [axes]\n",
        "\n",
        "    for i, column in enumerate(data.columns):\n",
        "        color = fill_color_dict[column]\n",
        "\n",
        "        # Boxplot\n",
        "        axes[i][0].boxplot(data[column].dropna(), vert=False, patch_artist=True,\n",
        "                        boxprops=dict(facecolor=color, color=color),\n",
        "                        medianprops=dict(color=\"black\"))\n",
        "        axes[i][0].set_title(f\"Boxplot of {column}\")\n",
        "        axes[i][0].set_xlabel(column)\n",
        "\n",
        "        # Histogram\n",
        "        axes[i][1].hist(data[column].dropna(), bins=20, color=color, alpha=0.7, edgecolor='black')\n",
        "        axes[i][1].set_title(f\"Histogram of {column}\")\n",
        "        axes[i][1].set_xlabel(column)\n",
        "\n",
        "    # Overall layout\n",
        "    fig.suptitle(\"Boxplot and Distribution Visualization for Each Numeric Column\", fontsize=16)\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.97])  # Adjust layout to fit title\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a26647",
      "metadata": {
        "id": "a1a26647"
      },
      "outputs": [],
      "source": [
        "#function for plotting categorical data distribution\n",
        "def categoric_dist_plot(data: pd.DataFrame):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Categorical pandas dataframe\n",
        "\n",
        "    Raises:\n",
        "        TypeError: The following columns are not categorical: {non_numeric_cols}\n",
        "        This is due to some of the columns are not categorical.\n",
        "\n",
        "    Returns:\n",
        "        plt: Plot of the categorical data distribution\n",
        "    \"\"\"\n",
        "    # Checks\n",
        "    ## Check if all columns are numeric\n",
        "    non_categoric_cols = [col for col in data.columns if pd.api.types.is_numeric_dtype(data[col])]\n",
        "    if non_categoric_cols:\n",
        "        raise TypeError(f\"The following columns are not categoric: {non_categoric_cols}\")\n",
        "\n",
        "    # Create subplots: one row for each categorical column\n",
        "    num_rows = len(data.columns)\n",
        "    fig, axes = plt.subplots(nrows=num_rows, ncols=1, figsize=(10, num_rows * 3), sharex=False)\n",
        "\n",
        "    # Flatten axes for easier handling if there's more than 1 row\n",
        "    axes = axes if num_rows > 1 else [axes]\n",
        "\n",
        "    # Plot each categorical distribution\n",
        "    for i, col in enumerate(data.columns):\n",
        "        counts = data[col].value_counts(dropna=False)  # Get the count values\n",
        "        counts.index = counts.index.astype(str) #convert the categorical values to strings since there are numerical categories\n",
        "\n",
        "        #Create the bar plot\n",
        "        axes[i].bar(counts.index, counts)\n",
        "\n",
        "        # Set title and labels\n",
        "        axes[i].set_title(f\"Distribution of {col}\", fontsize=12)\n",
        "        axes[i].set_ylabel(\"Count\")\n",
        "        axes[i].set_xlabel(\"Category\")\n",
        "\n",
        "        # Rotate x-axis labels for better readability\n",
        "        axes[i].tick_params(axis='x', rotation=90)\n",
        "\n",
        "    # Add an overall title and adjust layout\n",
        "    fig.suptitle(\"Bar Plots for Categorical Columns\", fontsize=16, y=1.02)\n",
        "    fig.tight_layout(h_pad=2.0)  # Adjust spacing between rows\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49cbad03",
      "metadata": {
        "id": "49cbad03"
      },
      "source": [
        "#### Splitting Data to Categorical and Numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faee940d",
      "metadata": {
        "id": "faee940d"
      },
      "outputs": [],
      "source": [
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "categorical_data = data.select_dtypes(exclude=[np.number])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99dde90",
      "metadata": {
        "id": "e99dde90"
      },
      "source": [
        "#### Numerical Data Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d894b39a",
      "metadata": {
        "id": "d894b39a"
      },
      "outputs": [],
      "source": [
        "numeric_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5498438",
      "metadata": {
        "id": "b5498438"
      },
      "outputs": [],
      "source": [
        "numeric_dist_plot(numeric_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2fb5ea",
      "metadata": {
        "id": "fe2fb5ea"
      },
      "source": [
        "#### Categorical Data Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96cc9693",
      "metadata": {
        "id": "96cc9693"
      },
      "outputs": [],
      "source": [
        "categorical_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b60c21",
      "metadata": {
        "id": "e4b60c21"
      },
      "outputs": [],
      "source": [
        "categoric_dist_plot(categorical_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7edf95bc",
      "metadata": {
        "id": "7edf95bc"
      },
      "source": [
        "### Key Insights\n",
        "#### Problems With the Data\n",
        "1. **Inconcistent Data Values**:\n",
        "   - The months in the data is inconsistent. There are 3 types of month in the data (e.g. Numerical, partial month name, and full month name)\n",
        "2. **Wierd Data Range**:\n",
        "   - There seems to be a negative number of Occupancy as seen in the graph, and that is a outlier since there is nothing such as a negative number of people.\n",
        "3. **Skewness**:\n",
        "   - There are some skewness in the month data where there are mostly data from january. Which may impact model's performance/\n",
        "   - The rest of the data are mostly uniform except for EnergyConsumption where it has a normal distribution.\n",
        "\n",
        "#### Small Fixes\n",
        "4. **Data Types**:\n",
        "- Changing the data type of \"EnergyConsumption\" from `object` to `float64`\n",
        "- Removed Missing values from the data\n",
        "\n",
        "#### Next Steps\n",
        "- Further Clean the data due to inconsistencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d05511",
      "metadata": {
        "id": "79d05511"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "- Standardizing the \"month\" data\n",
        "- Cleaning the negative number of occupancy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66811a88",
      "metadata": {
        "id": "66811a88"
      },
      "source": [
        "### Standardizing the \"month\" data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd10059",
      "metadata": {
        "id": "bdd10059"
      },
      "source": [
        "#### String to month number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1649e8b5",
      "metadata": {
        "id": "1649e8b5"
      },
      "outputs": [],
      "source": [
        "def str_to_month(String: str) -> str:\n",
        "    \"\"\"This function converts a string to a month type. The string can be in the format of \"Jan\", \"Feb\", etc. or \"January\", \"February\", etc.\n",
        "    It will return the month number as a string. If the string is not in the correct format, it will return NaT.\n",
        "\n",
        "    Args:\n",
        "        String (str): The string to be converted to a month number.\n",
        "\n",
        "    Raises:\n",
        "        TypeError: 'The following value is not a string: {String}'\n",
        "        This is due to the fact that the input is not a string.\n",
        "\n",
        "    Returns:\n",
        "        str: The month number as a string or NaT if the conversion failed.\n",
        "    \"\"\"\n",
        "    # Check\n",
        "    ## Check if the text is a string\n",
        "    if not isinstance(String, str):\n",
        "        raise TypeError(f\"The following value is not a string: {String}\")\n",
        "\n",
        "    try:\n",
        "        # If the string is already in a number format, convert it to a month number\n",
        "        if String.isdecimal():\n",
        "            # Check if the string is a number between 1 and 12 (january to december)\n",
        "            num = int(String)\n",
        "            if 1 <= num <= 12:\n",
        "                dt = pd.to_datetime(num, format = '%m')\n",
        "                return f\"{dt.month:01d}\"\n",
        "            else:\n",
        "                return pd.NaT\n",
        "\n",
        "        # Try full month name\n",
        "        try:\n",
        "            dt = pd.to_datetime(String, format = '%B')  # e.g., 'January'\n",
        "        except ValueError:\n",
        "            dt = pd.to_datetime(String, format = '%b')  # e.g., 'Jan'\n",
        "\n",
        "        return f\"{dt.month:01d}\"\n",
        "\n",
        "    except Exception:\n",
        "        #Return NA if the string conversion failed\n",
        "        return pd.NaT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69570cbb",
      "metadata": {
        "id": "69570cbb"
      },
      "source": [
        "#### Apply the month to number function to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b3ca30",
      "metadata": {
        "id": "39b3ca30"
      },
      "outputs": [],
      "source": [
        "data[\"Month\"] = data[\"Month\"].apply(str_to_month)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d938350",
      "metadata": {
        "id": "9d938350"
      },
      "source": [
        "### Cleaning the data with negative occupancy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ebc6f0f",
      "metadata": {
        "id": "5ebc6f0f"
      },
      "source": [
        "#### Check if the data is present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c645993",
      "metadata": {
        "id": "3c645993"
      },
      "outputs": [],
      "source": [
        "data[data[\"Occupancy\"] < 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd4bfbe7",
      "metadata": {
        "id": "cd4bfbe7"
      },
      "source": [
        "There is an occupancy with -5 person which is impossible since there is no such thing as negative number of persons. So removing the data would be beneficial for a cleaner data fror the deep learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "278866b3",
      "metadata": {
        "id": "278866b3"
      },
      "outputs": [],
      "source": [
        "data = data.drop(data[data[\"Occupancy\"] < 0].index).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e43485dc",
      "metadata": {
        "id": "e43485dc"
      },
      "source": [
        "### Rechecking the distribution of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3ecfdc",
      "metadata": {
        "id": "cc3ecfdc"
      },
      "outputs": [],
      "source": [
        "categorical_data = data.select_dtypes(exclude=[np.number])\n",
        "numeric_data = data.select_dtypes(include=[np.number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a79f0d5c",
      "metadata": {
        "id": "a79f0d5c"
      },
      "outputs": [],
      "source": [
        "numeric_dist_plot(numeric_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f260746",
      "metadata": {
        "id": "3f260746"
      },
      "outputs": [],
      "source": [
        "categoric_dist_plot(categorical_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e818604",
      "metadata": {
        "id": "2e818604"
      },
      "source": [
        "### Summary Of Data Cleaning\n",
        "#### Key Insights:\n",
        "1. **Inconsistent Data Values**:\n",
        "    - The \"Month\" column had inconsistent formats (e.g., numeric, full names, abbreviations), which were standardized.\n",
        "2. **Outliers**:\n",
        "    - Negative values in the \"Occupancy\" column were identified and removed.\n",
        "\n",
        "3. **Skewness**:\n",
        "    - The \"EnergyConsumption\" column has a normal distribution, while other numerical columns show varying degrees of skewness.\n",
        "\n",
        "4. **Categorical Data**:\n",
        "    - Some categorical columns, such as \"Holiday\" and \"HVACUsage,\" have imbalanced distributions, which may impact model performance.\n",
        "\n",
        "5. **Data Cleaning**:\n",
        "    - After cleaning, the dataset is now consistent and ready for preprocessing and modeling.\n",
        "\n",
        "#### Next Steps:\n",
        "- Scale numerical data to ensure uniformity.\n",
        "- Encode categorical data for compatibility with machine learning models.\n",
        "- Split the data into training, validation, and testing sets for model development.\n",
        "\n",
        "**At this point**:\n",
        "- The dataset is now clean and ready for further preprocessing or modeling.\n",
        "- The handling of missing values and standardization of date formats ensures consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ea9d77",
      "metadata": {
        "id": "e6ea9d77"
      },
      "source": [
        "## Data Propressing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85087962",
      "metadata": {
        "id": "85087962"
      },
      "source": [
        "### Spitting data to train, test, and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7cd7cb",
      "metadata": {
        "id": "7b7cd7cb"
      },
      "source": [
        "#### Split data to the predictor and outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06772ba",
      "metadata": {
        "id": "b06772ba"
      },
      "outputs": [],
      "source": [
        "x_data = data.drop(columns=[\"EnergyConsumption\"])\n",
        "y_data = data[\"EnergyConsumption\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6b1272",
      "metadata": {
        "id": "2c6b1272"
      },
      "outputs": [],
      "source": [
        "# Check the columns\n",
        "x_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea0ab74",
      "metadata": {
        "id": "3ea0ab74"
      },
      "outputs": [],
      "source": [
        "y_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deb467cd",
      "metadata": {
        "id": "deb467cd"
      },
      "source": [
        "####  Split to train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaff2c12",
      "metadata": {
        "id": "aaff2c12"
      },
      "outputs": [],
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c504c6",
      "metadata": {
        "id": "f0c504c6"
      },
      "source": [
        "#### Split to train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43181a6",
      "metadata": {
        "id": "f43181a6"
      },
      "outputs": [],
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
        "train_x.shape, val_x.shape, train_y.shape, val_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aa6048e",
      "metadata": {
        "id": "1aa6048e"
      },
      "source": [
        "So after splitting the data we will obtain the following:\n",
        "<table>\n",
        "<tr>\n",
        "<th>Data</th>\n",
        "<th>Size</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Train</td>\n",
        "<td>788</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Validation</td>\n",
        "<td>197</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Test</td>\n",
        "<td>247</td>\n",
        "</tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1715cfd2",
      "metadata": {
        "id": "1715cfd2"
      },
      "source": [
        "### Scaling the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da301e2b",
      "metadata": {
        "id": "da301e2b"
      },
      "source": [
        "#### Scaling the numerical data\n",
        "\n",
        "All the numerical features will use min max scaling since there are no outliers, and the data is almost uniformly distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f72c93ef",
      "metadata": {
        "id": "f72c93ef"
      },
      "outputs": [],
      "source": [
        "hoursScaler = MinMaxScaler()\n",
        "tempScaler = MinMaxScaler()\n",
        "humidScaler = MinMaxScaler()\n",
        "squareScaler = MinMaxScaler()\n",
        "occupancyScaler = MinMaxScaler()\n",
        "renewableScaler = MinMaxScaler()\n",
        "energyScaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c72e6330",
      "metadata": {
        "id": "c72e6330"
      },
      "source": [
        "##### Apply to train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1aa514",
      "metadata": {
        "id": "5a1aa514"
      },
      "outputs": [],
      "source": [
        "# The x features\n",
        "train_x[\"Hour\"] = hoursScaler.fit_transform(train_x[[\"Hour\"]])\n",
        "train_x[\"Temperature\"] = tempScaler.fit_transform(train_x[[\"Temperature\"]])\n",
        "train_x[\"Humidity\"] = humidScaler.fit_transform(train_x[[\"Humidity\"]])\n",
        "train_x[\"SquareFootage\"] = squareScaler.fit_transform(train_x[[\"SquareFootage\"]])\n",
        "train_x[\"Occupancy\"] = occupancyScaler.fit_transform(train_x[[\"Occupancy\"]])\n",
        "train_x[\"RenewableEnergy\"] = renewableScaler.fit_transform(train_x[[\"RenewableEnergy\"]])\n",
        "\n",
        "# The y value\n",
        "train_y = energyScaler.fit_transform(train_y.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95decdc2",
      "metadata": {
        "id": "95decdc2"
      },
      "source": [
        "##### Apply to validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0a0bc3",
      "metadata": {
        "id": "7c0a0bc3"
      },
      "outputs": [],
      "source": [
        "# The x features\n",
        "val_x[\"Hour\"] = hoursScaler.transform(val_x[[\"Hour\"]])\n",
        "val_x[\"Temperature\"] = tempScaler.transform(val_x[[\"Temperature\"]])\n",
        "val_x[\"Humidity\"] = humidScaler.transform(val_x[[\"Humidity\"]])\n",
        "val_x[\"SquareFootage\"] = squareScaler.transform(val_x[[\"SquareFootage\"]])\n",
        "val_x[\"Occupancy\"] = occupancyScaler.transform(val_x[[\"Occupancy\"]])\n",
        "val_x[\"RenewableEnergy\"] = renewableScaler.transform(val_x[[\"RenewableEnergy\"]])\n",
        "\n",
        "# The y value\n",
        "val_y = energyScaler.transform(val_y.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdd18eb",
      "metadata": {
        "id": "1cdd18eb"
      },
      "source": [
        "##### Apply to test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a3305a",
      "metadata": {
        "id": "77a3305a"
      },
      "outputs": [],
      "source": [
        "# The x features\n",
        "test_x[\"Hour\"] = hoursScaler.transform(test_x[[\"Hour\"]])\n",
        "test_x[\"Temperature\"] = tempScaler.transform(test_x[[\"Temperature\"]])\n",
        "test_x[\"Humidity\"] = humidScaler.transform(test_x[[\"Humidity\"]])\n",
        "test_x[\"SquareFootage\"] = squareScaler.transform(test_x[[\"SquareFootage\"]])\n",
        "test_x[\"Occupancy\"] = occupancyScaler.transform(test_x[[\"Occupancy\"]])\n",
        "test_x[\"RenewableEnergy\"] = renewableScaler.transform(test_x[[\"RenewableEnergy\"]])\n",
        "\n",
        "# The y value\n",
        "test_y = energyScaler.transform(test_y.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1bd66e",
      "metadata": {
        "id": "de1bd66e"
      },
      "source": [
        "### Encoding the Categorical Data\n",
        "\n",
        "Binary Columns: `LightingUsage`, `HVACUsage`, `Holiday`\n",
        "\n",
        "Nominal Columns: `DayOfWeek`\n",
        "\n",
        "Ordinal Columns: `Month`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee1bfab5",
      "metadata": {
        "id": "ee1bfab5"
      },
      "outputs": [],
      "source": [
        "# The Values in the columns\n",
        "for col in categorical_data.columns:\n",
        "    print(f\"{col}: {categorical_data[col].unique()} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7525ca0c",
      "metadata": {
        "id": "7525ca0c"
      },
      "outputs": [],
      "source": [
        "binary_cols_1 = [\"Holiday\"]\n",
        "binary_cols_2 = [\"HVACUsage\", \"LightingUsage\"] # Use Label enconder (On or Off)\n",
        "nominal_cols = [\"DayOfWeek\"] # Use OneHotEncoder\n",
        "ordinal_cols = [\"Month\"] # Use OrdinalEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad55d0b9",
      "metadata": {
        "id": "ad55d0b9"
      },
      "source": [
        "#### Encoder Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecb0e26",
      "metadata": {
        "id": "0ecb0e26"
      },
      "outputs": [],
      "source": [
        "bin_enc_1 = LabelEncoder()\n",
        "bin_enc_2 = LabelEncoder()\n",
        "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
        "ordinal_enc = OrdinalEncoder(categories=[[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]], handle_unknown=\"use_encoded_value\", unknown_value=-1).set_output(transform=\"pandas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a33b3f5",
      "metadata": {
        "id": "2a33b3f5"
      },
      "source": [
        "#### Transforming the Train Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217f0214",
      "metadata": {
        "id": "217f0214"
      },
      "source": [
        "##### Binary Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77a3edc",
      "metadata": {
        "id": "c77a3edc"
      },
      "outputs": [],
      "source": [
        "bin_data = pd.concat([train_x[binary_cols_1].apply(bin_enc_1.fit_transform), train_x[binary_cols_2].apply(bin_enc_2.fit_transform)], axis=1)\n",
        "bin_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958ac133",
      "metadata": {
        "id": "958ac133"
      },
      "source": [
        "##### Nominal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862596e2",
      "metadata": {
        "id": "862596e2"
      },
      "outputs": [],
      "source": [
        "nominal_data = ohe.fit_transform(train_x[nominal_cols])\n",
        "nominal_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a96ece",
      "metadata": {
        "id": "12a96ece"
      },
      "source": [
        "##### Ordinal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a091be5b",
      "metadata": {
        "id": "a091be5b"
      },
      "outputs": [],
      "source": [
        "ordinal_data = ordinal_enc.fit_transform(train_x[ordinal_cols])\n",
        "ordinal_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f6e7e2c",
      "metadata": {
        "id": "5f6e7e2c"
      },
      "source": [
        "##### Reunite the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42d73b6",
      "metadata": {
        "id": "b42d73b6"
      },
      "outputs": [],
      "source": [
        "train_x = pd.concat([train_x.drop(columns=binary_cols_1 + binary_cols_2 + nominal_cols + ordinal_cols), bin_data, nominal_data, ordinal_data], axis=1)\n",
        "train_x.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f845e2fd",
      "metadata": {
        "id": "f845e2fd"
      },
      "source": [
        "#### Transforming the Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e140a328",
      "metadata": {
        "id": "e140a328"
      },
      "source": [
        "##### Binary Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7604458",
      "metadata": {
        "id": "b7604458"
      },
      "outputs": [],
      "source": [
        "bin_data = pd.concat([val_x[binary_cols_1].apply(bin_enc_1.transform), val_x[binary_cols_2].apply(bin_enc_2.transform)], axis=1)\n",
        "bin_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e5c5669",
      "metadata": {
        "id": "9e5c5669"
      },
      "source": [
        "##### Nominal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc6d86e",
      "metadata": {
        "id": "5fc6d86e"
      },
      "outputs": [],
      "source": [
        "nominal_data = ohe.transform(val_x[nominal_cols])\n",
        "nominal_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2f4906",
      "metadata": {
        "id": "8a2f4906"
      },
      "source": [
        "##### Ordinal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a450a3",
      "metadata": {
        "id": "02a450a3"
      },
      "outputs": [],
      "source": [
        "ordinal_data = ordinal_enc.transform(val_x[ordinal_cols])\n",
        "ordinal_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08071408",
      "metadata": {
        "id": "08071408"
      },
      "source": [
        "##### Reunite the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2af455",
      "metadata": {
        "id": "be2af455"
      },
      "outputs": [],
      "source": [
        "val_x = pd.concat([val_x.drop(columns=binary_cols_1 + binary_cols_2 + nominal_cols + ordinal_cols), bin_data, nominal_data, ordinal_data], axis=1)\n",
        "val_x.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc9e3d1",
      "metadata": {
        "id": "9cc9e3d1"
      },
      "source": [
        "#### Transforming the Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f81ff2",
      "metadata": {
        "id": "65f81ff2"
      },
      "source": [
        "##### Binary Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e542c5d0",
      "metadata": {
        "id": "e542c5d0"
      },
      "outputs": [],
      "source": [
        "bin_data = pd.concat([test_x[binary_cols_1].apply(bin_enc_1.transform), test_x[binary_cols_2].apply(bin_enc_2.transform)], axis=1)\n",
        "bin_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2fb33d",
      "metadata": {
        "id": "2f2fb33d"
      },
      "source": [
        "##### Nominal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d84562a",
      "metadata": {
        "id": "7d84562a"
      },
      "outputs": [],
      "source": [
        "nominal_data = ohe.transform(test_x[nominal_cols])\n",
        "nominal_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e53e70",
      "metadata": {
        "id": "15e53e70"
      },
      "source": [
        "##### Ordinal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee00aba",
      "metadata": {
        "id": "9ee00aba"
      },
      "outputs": [],
      "source": [
        "ordinal_data = ordinal_enc.transform(test_x[ordinal_cols])\n",
        "ordinal_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ad86ff",
      "metadata": {
        "id": "17ad86ff"
      },
      "source": [
        "##### Reunite the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae123df",
      "metadata": {
        "id": "eae123df"
      },
      "outputs": [],
      "source": [
        "test_x = pd.concat([test_x.drop(columns=binary_cols_1 + binary_cols_2 + nominal_cols + ordinal_cols), bin_data, nominal_data, ordinal_data], axis=1)\n",
        "test_x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7a6d668",
      "metadata": {
        "id": "a7a6d668"
      },
      "outputs": [],
      "source": [
        "test_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d12f1b",
      "metadata": {
        "id": "e1d12f1b"
      },
      "source": [
        "## Model making"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb072ed",
      "metadata": {
        "id": "9cb072ed"
      },
      "source": [
        "### Baseline Model\n",
        "\n",
        "We will develop a Sequential Model And Functional Model\n",
        "\n",
        "Requirements:\n",
        "1. Relu Activation\n",
        "2. The minimum Number of neurons is 2x the input data dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0197386",
      "metadata": {
        "id": "d0197386"
      },
      "source": [
        "#### Sequential_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7acbaec3",
      "metadata": {
        "id": "7acbaec3"
      },
      "source": [
        "##### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139871a5",
      "metadata": {
        "id": "139871a5"
      },
      "outputs": [],
      "source": [
        "seq_model = Sequential()\n",
        "seq_model.add(Dense(64, input_dim=train_x.shape[1], activation='relu'))\n",
        "seq_model.add(Dense(64, activation='relu'))\n",
        "seq_model.add(Dense(1, activation='relu')) #one numeric output column\n",
        "seq_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "seq_model.fit(train_x, train_y, epochs=10, batch_size=32, validation_data=(val_x, val_y), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fabe13c2",
      "metadata": {
        "id": "fabe13c2"
      },
      "outputs": [],
      "source": [
        "seq_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14da525d",
      "metadata": {
        "id": "14da525d"
      },
      "source": [
        "##### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082a15d3",
      "metadata": {
        "id": "082a15d3"
      },
      "outputs": [],
      "source": [
        "seq_pred = seq_model.predict(test_x)\n",
        "print(f\"R2 Score: \\t{r2_score(test_y, seq_pred)}\")\n",
        "print(f\"MSE: \\t \\t{mean_squared_error(test_y, seq_pred)}\")\n",
        "print(f\"MAE: \\t \\t{mean_absolute_error(test_y, seq_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d2914e",
      "metadata": {
        "id": "48d2914e"
      },
      "source": [
        "The model will undergo hyperparameter tuning to further optimize the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7740cc",
      "metadata": {
        "id": "7b7740cc"
      },
      "source": [
        "#### Functional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19382386",
      "metadata": {
        "id": "19382386"
      },
      "source": [
        "##### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b971715",
      "metadata": {
        "id": "8b971715"
      },
      "outputs": [],
      "source": [
        "# Input layer\n",
        "inputs = Input(shape=(train_x.shape[1],))\n",
        "\n",
        "# Making hidden layers\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1, activation='relu')(x)  # one numeric output column\n",
        "\n",
        "#Compile the model\n",
        "func_model = Model(inputs = inputs, outputs = output)\n",
        "func_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "func_model.fit(train_x, train_y, epochs=10, batch_size=32, validation_data=(val_x, val_y), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be93e450",
      "metadata": {
        "id": "be93e450"
      },
      "outputs": [],
      "source": [
        "func_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaaa5c88",
      "metadata": {
        "id": "aaaa5c88"
      },
      "source": [
        "##### Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f951d9",
      "metadata": {
        "id": "99f951d9"
      },
      "outputs": [],
      "source": [
        "func_pred = func_model.predict(test_x)\n",
        "print(f\"R2 Score: \\t{r2_score(test_y, func_pred)}\")\n",
        "print(f\"MSE: \\t \\t{mean_squared_error(test_y, func_pred)}\")\n",
        "print(f\"MAE: \\t \\t{mean_absolute_error(test_y, func_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d78cb302",
      "metadata": {
        "id": "d78cb302"
      },
      "source": [
        "#### Compare both model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5c8ec2",
      "metadata": {
        "id": "fa5c8ec2"
      },
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\"Metrics\": [\"R2 Score\", \"MSE\", \"MAE\"],\n",
        "                          \"Sequential Model\": [r2_score(test_y, seq_pred), mean_squared_error(test_y, seq_pred), mean_absolute_error(test_y, seq_pred)],\n",
        "                          \"Functional Model\": [r2_score(test_y, func_pred), mean_squared_error(test_y, func_pred), mean_absolute_error(test_y, func_pred)]})\n",
        "comparison.set_index(\"Metrics\", inplace=True)\n",
        "comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab16a3d8",
      "metadata": {
        "id": "ab16a3d8"
      },
      "source": [
        "There is no difference in results between the sequential and functional model. Since there are no difference in the model architecture however different model making."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501bb774",
      "metadata": {
        "id": "501bb774"
      },
      "source": [
        "### Proposed Model\n",
        "\n",
        "We will develop a Sequential Model And Functional Model with hyperparameter tuning using optuna.\n",
        "\n",
        "Requirements:\n",
        "1. Relu Activation\n",
        "2. The minimum Number of neurons is 2x the input data dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5ad4b0f",
      "metadata": {
        "id": "c5ad4b0f"
      },
      "source": [
        "#### Sequential Model\n",
        "\n",
        "We will use optuna for gridsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e834049",
      "metadata": {
        "id": "9e834049"
      },
      "source": [
        "##### Neural Architecture Search Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbd9744",
      "metadata": {
        "id": "cfbd9744"
      },
      "outputs": [],
      "source": [
        "def seq_objective(trial):\n",
        "    \"\"\"This function is used to optimize the hyperparameters of the sequential model using Optuna.\n",
        "    It takes a trial object as input and returns the R2 score of the model on the validation set.\n",
        "\n",
        "    Args:\n",
        "        trial (_Optuna trial object_): Optuna trial object\n",
        "\n",
        "    Returns:\n",
        "        R2_score: R2 score of the model on the validation set\n",
        "    \"\"\"\n",
        "    # Sequential model\n",
        "    # Suggest hyperparameters\n",
        "    ## Input Layer\n",
        "    num_layers = trial.suggest_int('n_layers', 1, 10)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(trial.suggest_int('input_l_n_neuron', 17, 256),\n",
        "                    activation=trial.suggest_categorical('input_l_activation', ['relu', 'linear', 'elu', 'gelu']),\n",
        "                    input_dim=train_x.shape[1]\n",
        "                    ))\n",
        "\n",
        "    ## Hidden Layer\n",
        "    for i in range(num_layers):\n",
        "        n_neurons = trial.suggest_int(f'l{i}_n_neuron', 16, 256)\n",
        "        activation = trial.suggest_categorical(f'l{i}_activation', ['relu', 'linear', 'elu', 'gelu'])\n",
        "        model.add(Dense(n_neurons, activation=activation))\n",
        "\n",
        "    ## dropout layer\n",
        "    if trial.suggest_categorical('dropout', [True, False]):\n",
        "        model.add(Dropout(trial.suggest_float('dropout_rate', 0.1, 0.5)))\n",
        "\n",
        "    ## Output Layer\n",
        "    activation = trial.suggest_categorical(f'output_l_activation', ['relu', 'linear', 'elu', 'gelu'])\n",
        "    model.add(Dense(1, activation=activation))  # output layer\n",
        "\n",
        "    ## Choose optimizer\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
        "    model.compile(\n",
        "        optimizer=optimizer_name,\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mse']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_x, train_y,\n",
        "              validation_data=(val_x, val_y),\n",
        "              epochs=10,\n",
        "              batch_size= trial.suggest_categorical('batch_size', [32, 64, 128]),\n",
        "              verbose=0)\n",
        "\n",
        "    # Evaluate\n",
        "    model_pred = model.predict(val_x)\n",
        "    r2_score_val = r2_score(val_y, model_pred)\n",
        "    return r2_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c68bafd",
      "metadata": {
        "id": "6c68bafd"
      },
      "source": [
        "##### Start the search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b016500",
      "metadata": {
        "id": "9b016500"
      },
      "outputs": [],
      "source": [
        "seq_study = optuna.create_study(direction=\"maximize\") # Maximize the R2 score\n",
        "seq_study.optimize(seq_objective, n_trials=5000, show_progress_bar=True) #since we are using gpu we can try more combinations due to the faster processing time\n",
        "\n",
        "print(\"Number of finished trials: \", len(seq_study.trials))\n",
        "print(\"Best seq_trial:\")\n",
        "\n",
        "seq_trial = seq_study.best_trial\n",
        "\n",
        "print(\"\\tValue: \", seq_trial.value)\n",
        "print(\"\\tParams: \")\n",
        "\n",
        "for key, value in seq_trial.params.items():\n",
        "    print(f\"\\t\\t{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e1552fe",
      "metadata": {
        "id": "8e1552fe"
      },
      "source": [
        "#### Functional Model\n",
        "\n",
        "We will use optuna for gridsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a5112c",
      "metadata": {
        "id": "37a5112c"
      },
      "source": [
        "##### Neural Architechture Search Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231bc995",
      "metadata": {
        "id": "231bc995"
      },
      "outputs": [],
      "source": [
        "def func_objective(trial):\n",
        "    \"\"\"This function is used to optimize the hyperparameters of the functional model using Optuna.\n",
        "    It takes a trial object as input and returns the R2 score of the model on the validation set.\n",
        "\n",
        "    Args:\n",
        "        trial (_Optuna trial object_): Optuna trial object\n",
        "\n",
        "    Returns:\n",
        "        R2_score: R2 score of the model on the validation set\n",
        "    \"\"\"\n",
        "    # Fucntional model\n",
        "    # Suggest hyperparameters\n",
        "    ## Input Layer\n",
        "    num_layers = trial.suggest_int('n_layers', 1, 10)\n",
        "    input = Input(shape=(train_x.shape[1],))\n",
        "\n",
        "    ## Hidden Layer\n",
        "    x = Dense(trial.suggest_int(f'input_l_n_neuron', 16, 256),\n",
        "              activation = trial.suggest_categorical('input_l_activation', ['relu', 'linear', 'elu', 'gelu']))(input)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        n_neurons = trial.suggest_int(f'l{i}_n_neuron', 16, 256)\n",
        "        activation = trial.suggest_categorical(f'l{i}_activation', ['relu', 'linear', 'elu', 'gelu'])\n",
        "        x = Dense(n_neurons, activation=activation)(x)\n",
        "\n",
        "    ## dropout layer\n",
        "    if trial.suggest_categorical('dropout', [True, False]):\n",
        "        x = Dropout(trial.suggest_float('dropout_rate', 0.1, 0.5))(x)\n",
        "\n",
        "    ## Output Layer\n",
        "    activation = trial.suggest_categorical(f'output_l_activation', ['relu', 'linear', 'elu', 'gelu'])\n",
        "    output = Dense(1, activation = activation)(x)  # output layer\n",
        "\n",
        "    ## Choose optimizer\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizer_name,\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mse']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_x, train_y,\n",
        "              validation_data=(val_x, val_y),\n",
        "              epochs=10,\n",
        "              batch_size=trial.suggest_categorical('batch_size', [32, 64, 128]),\n",
        "              verbose=0)\n",
        "\n",
        "    # Evaluate\n",
        "    model_pred = model.predict(val_x)\n",
        "    r2_score_val = r2_score(val_y, model_pred)\n",
        "    return r2_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cac869e7",
      "metadata": {
        "id": "cac869e7"
      },
      "source": [
        "##### Start the search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd4a039",
      "metadata": {
        "id": "5fd4a039"
      },
      "outputs": [],
      "source": [
        "func_study = optuna.create_study(direction=\"maximize\") # Maximize the R2 score\n",
        "func_study.optimize(func_objective, n_trials=5000, show_progress_bar=True) #since we are using gpu we can try more combinations due to the faster processing time\n",
        "\n",
        "print(\"Number of finished trials: \", len(func_study.trials))\n",
        "print(\"Best trial:\")\n",
        "\n",
        "func_trial = func_study.best_trial\n",
        "\n",
        "print(\"\\tValue: \", func_trial.value)\n",
        "print(\"\\tParams: \")\n",
        "\n",
        "for key, value in func_trial.params.items():\n",
        "    print(f\"\\t\\t{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c19bd5",
      "metadata": {
        "id": "81c19bd5"
      },
      "source": [
        "#### Model builder function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbec915",
      "metadata": {
        "id": "2bbec915"
      },
      "source": [
        "##### Sequential model builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47b2cec",
      "metadata": {
        "id": "c47b2cec"
      },
      "outputs": [],
      "source": [
        "def seq_model_builder(best_params: dict, input_dim: int):\n",
        "    \"\"\"This function builds a sequential model based on the best parameters found by Optuna.\n",
        "       It takes the best parameters and the input dimension as input and returns the model.\n",
        "\n",
        "    Args:\n",
        "        best_params (dict): Dictionary of the best parameters found by Optuna\n",
        "        input_dim (int): Input dimension of the model\n",
        "        The input dimension should be greater than 0.\n",
        "\n",
        "    Raises:\n",
        "        TypeError: 'best_params should be a dictionary' try best_params.params\n",
        "        TypeError: 'input_dim should be an integer'\n",
        "        ValueError: 'input_dim invalid. should be greater than 0'\n",
        "        negative dimmentions are not allowed\n",
        "\n",
        "    Returns:\n",
        "        model: The sequential model from the best parameters\n",
        "    \"\"\"\n",
        "    # Type Check\n",
        "    if not isinstance(best_params, dict):\n",
        "        raise TypeError(\"best_params should be a dictionary\")\n",
        "    if not isinstance(input_dim, int):\n",
        "        raise TypeError(\"input_dim should be an integer\")\n",
        "    if input_dim <= 0:\n",
        "        raise ValueError(\"input_dim invalid. should be greater than 0\")\n",
        "\n",
        "    # Input Layer\n",
        "    num_layers = best_params[\"n_layers\"]\n",
        "    model = Sequential()\n",
        "    model.add(Dense(best_params['input_l_n_neuron'],\n",
        "                    activation=best_params['input_l_activation'],\n",
        "                    input_dim=input_dim\n",
        "                    ))\n",
        "\n",
        "    # Hidden Layer\n",
        "    for i in range(num_layers):\n",
        "        n_neurons = best_params[f'l{i}_n_neuron']\n",
        "        activation = best_params[f'l{i}_activation']\n",
        "        model.add(Dense(n_neurons, activation=activation))\n",
        "\n",
        "    # dropout layer\n",
        "    if best_params['dropout']:\n",
        "        model.add(Dropout(best_params['dropout_rate']))\n",
        "\n",
        "    # Output Layer\n",
        "    activation = best_params['output_l_activation']\n",
        "    model.add(Dense(1, activation=activation))  # output layer\n",
        "\n",
        "    # Choose optimizer\n",
        "    optimizer_name = best_params['optimizer']\n",
        "    model.compile(\n",
        "        optimizer=optimizer_name,\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mse']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "539a43ec",
      "metadata": {
        "id": "539a43ec"
      },
      "source": [
        "##### Functional model builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9bf0d9",
      "metadata": {
        "id": "6d9bf0d9"
      },
      "outputs": [],
      "source": [
        "def func_model_builder(best_params: dict, input_dim: int):\n",
        "    \"\"\"This function builds a functional model based on the best parameters found by Optuna.\n",
        "       It takes the best parameters and the input dimension as input and returns the model.\n",
        "\n",
        "    Args:\n",
        "        best_params (dict): Dictionary of the best parameters found by Optuna\n",
        "        input_dim (int): Input dimension of the model\n",
        "        The input dimension should be greater than 0.\n",
        "\n",
        "    Raises:\n",
        "        TypeError: 'best_params should be a dictionary' try best_params.params\n",
        "        TypeError: 'input_dim should be an integer'\n",
        "        ValueError: 'input_dim invalid. should be greater than 0'\n",
        "        negative dimmentions are not allowed\n",
        "\n",
        "    Returns:\n",
        "        model: The functional model from the best parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Type Check\n",
        "    if not isinstance(best_params, dict):\n",
        "        raise TypeError(\"best_params should be a dictionary\")\n",
        "    if not isinstance(input_dim, int):\n",
        "        raise TypeError(\"input_dim should be an integer\")\n",
        "    if input_dim <= 0:\n",
        "        raise ValueError(\"input_dim invalid. should be greater than 0\")\n",
        "\n",
        "    ## Input Layer\n",
        "    num_layers = best_params[\"n_layers\"]\n",
        "    input = Input(shape=(input_dim,))\n",
        "\n",
        "    ## Hidden Layer\n",
        "    x = Dense(best_params['input_l_n_neuron'],\n",
        "              activation = best_params['input_l_activation'])(input)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        n_neurons = best_params[f'l{i}_n_neuron']\n",
        "        activation = best_params[f'l{i}_activation']\n",
        "        x = Dense(n_neurons, activation=activation)(x)\n",
        "\n",
        "    ## dropout layer\n",
        "    if best_params['dropout']:\n",
        "        x = Dropout(best_params['dropout_rate'])(x)\n",
        "\n",
        "    ## Output Layer\n",
        "    activation = best_params['output_l_activation']\n",
        "    output = Dense(1, activation = activation)(x)  # output layer\n",
        "\n",
        "    ## Choose optimizer\n",
        "    optimizer_name = best_params['optimizer']\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizer_name,\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mse']\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a48660",
      "metadata": {
        "id": "b3a48660"
      },
      "source": [
        "#### Test the models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e52683",
      "metadata": {
        "id": "03e52683"
      },
      "source": [
        "##### Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef77e89a",
      "metadata": {
        "id": "ef77e89a"
      },
      "outputs": [],
      "source": [
        "seq_model = seq_model_builder(seq_trial.params, train_x.shape[1])\n",
        "seq_model.fit(train_x, train_y, epochs=10, batch_size=32, validation_data=(val_x, val_y), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d5fcbb",
      "metadata": {
        "id": "07d5fcbb"
      },
      "source": [
        "##### Fucntional Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb911d60",
      "metadata": {
        "id": "fb911d60"
      },
      "outputs": [],
      "source": [
        "func_model = func_model_builder(func_trial.params, train_x.shape[1])\n",
        "func_model.fit(train_x, train_y, epochs=10, batch_size=32, validation_data=(val_x, val_y), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa704ad0",
      "metadata": {
        "id": "aa704ad0"
      },
      "source": [
        "#### Evaluate and Compare Both Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e4a13c",
      "metadata": {
        "id": "52e4a13c"
      },
      "source": [
        "##### R<sup>2</sup> Score, MSE, MAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa6f500",
      "metadata": {
        "id": "baa6f500"
      },
      "outputs": [],
      "source": [
        "seq_pred = seq_model.predict(test_x)\n",
        "func_pred = func_model.predict(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30927961",
      "metadata": {
        "id": "30927961"
      },
      "source": [
        "To evaluate the performance of the models, both a Sequential and a Functional neural network architecture were trained and finetuned using the same dataset. The evaluation metrics used were R Score, Mean Squared Error (MSE), and Mean Absolute Error (MAE). The results are summarized in the table below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1585a55",
      "metadata": {
        "id": "e1585a55"
      },
      "outputs": [],
      "source": [
        "NAS_comparison = pd.DataFrame({\"Metrics\": [\"R2 Score\", \"MSE\", \"MAE\"],\n",
        "                          \"Sequential Model\": [r2_score(test_y, seq_pred), mean_squared_error(test_y, seq_pred), mean_absolute_error(test_y, seq_pred)],\n",
        "                          \"Functional Model\": [r2_score(test_y, func_pred), mean_squared_error(test_y, func_pred), mean_absolute_error(test_y, func_pred)]})\n",
        "NAS_comparison.set_index(\"Metrics\", inplace=True)\n",
        "NAS_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53aae114",
      "metadata": {
        "id": "53aae114"
      },
      "outputs": [],
      "source": [
        "comparison = comparison.rename(columns={\"Sequential Model\": \"Sequential Model (Before NAS)\", \"Functional Model\": \"Functional Model (Before NAS)\"})\n",
        "NAS_comparison = NAS_comparison.rename(columns={\"Sequential Model\": \"Sequential Model (After NAS)\", \"Functional Model\": \"Functional Model (After NAS)\"})\n",
        "pd.concat([comparison, NAS_comparison], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "410e5471",
      "metadata": {
        "id": "410e5471"
      },
      "source": [
        "##### Model Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a85f58",
      "metadata": {
        "id": "56a85f58"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(func_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b24a8001",
      "metadata": {
        "id": "b24a8001"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(seq_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c998c163",
      "metadata": {
        "id": "c998c163"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c958e9",
      "metadata": {
        "id": "25c958e9"
      },
      "source": [
        "### Comparison before and after NAS\n",
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <td>Metrics</td>\n",
        "      <td>Sequential Model <b style=\"color:red\">(Before NAS)</b></td>\n",
        "      <td>Functional Model <b style=\"color:red\">(Before NAS)</b></td>\n",
        "      <td>Sequential Model <b style=\"color:green\">(After NAS)</b></td>\n",
        "      <td>Functional Model <b style=\"color:green\">(After NAS)</b></td>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>R2 Score</th>\n",
        "      <td>0.233671</td>\n",
        "      <td>0.211576</td>\n",
        "      <td>0.168453</td>\n",
        "      <td>0.195303</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MSE</th>\n",
        "      <td>0.031701</td>\n",
        "      <td>0.032615</td>\n",
        "      <td>0.034399</td>\n",
        "      <td>0.033288</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MAE</th>\n",
        "      <td>0.141460</td>\n",
        "      <td>0.143669</td>\n",
        "      <td>0.152042</td>\n",
        "      <td>0.139835</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>\n",
        "\n",
        "After applying NAS, the Sequential models performance slightly declined across all metrics, especially in R and MAE. In contrast, the Functional model showed a slight improvement in MAE and R, suggesting it benefited more from NAS optimization. However, the changes were relatively small, highlighting the consistency of both models.\n",
        "\n",
        "### Overall Model Performance\n",
        "The results show that both models achieved very **similar performance** across all three metrics. The Sequential model is **slightly** outperformed by the Functional model in terms of **R Score and MSE**, indicating a marginally better fit and lower error variance. However, the Functional model had a slightly lower MAE, suggesting it made more accurate predictions on average.\n",
        "<table>\n",
        "<tr>\n",
        "<th>Aspect</th>\n",
        "<th>Sequential Model (After NAS)</th>\n",
        "<th>Functional Model</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Fit</td>\n",
        "<td>Slightly <b>better</b></td>\n",
        "<td>Slightly <b>worse</b></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Error Variance</td>\n",
        "<td>Slightly <b>lower</b></td>\n",
        "<td>Slightly <b>higher</b></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Prediction Accuracy</td>\n",
        "<td>Slightly <b>less</b></td>\n",
        "<td>Slightly <b>more</b></td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "### Model Architecture\n",
        "While the performance differences are minimal, the Functional model remains advantageous by having a smaller model with 4 layers(including input and output) and less number of parameters. a comparison summary can be seen below:\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th>Specification</th>\n",
        "<th>Sequential Model</th>\n",
        "<th>Functional Model</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Number of layers</td>\n",
        "<td>13</td>\n",
        "<td>4</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Number of hidden layers</td>\n",
        "<td>11</td>\n",
        "<td>2</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Number of parameters</td>\n",
        "<td>213,682</td>\n",
        "<td>6,015</td>\n",
        "</tr>\n",
        "</table>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}